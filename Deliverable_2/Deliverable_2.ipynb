{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithms for Data Science - CS 676\n",
        "## Project 1 - Deliverable 2\n",
        "## Ali Inamdar"
      ],
      "metadata": {
        "id": "p4NsGZdYKJxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing all the libraries required for this deliverable."
      ],
      "metadata": {
        "id": "KS6RiW8kKhhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "v9D_wUMWJzTs"
      },
      "outputs": [],
      "source": [
        "#Importing all librariers for this deliverable\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importing Serp API & Hugging Face tokens."
      ],
      "metadata": {
        "id": "hQraya2aR0Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hugging Face Access Token\n",
        "login(token=\"Hugging FAce Token \")"
      ],
      "metadata": {
        "id": "K3qKBJF1NR_B"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Serp API Key\n",
        "from google.colab import userdata\n",
        "Ali_serp_api = userdata.get('Ali_Serp_API')"
      ],
      "metadata": {
        "id": "MWsM_CgCQmgN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Google fact check API Key\n",
        "Ali_google_api = userdata.get('Ali_google_api')"
      ],
      "metadata": {
        "id": "XhuJj2WlVu-2"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Creating the Class function."
      ],
      "metadata": {
        "id": "xMNfsbwXSC7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class URLValidator:\n",
        "    \"\"\"\n",
        "    A production-ready URL validation class that evaluates the credibility of a webpage\n",
        "    using multiple factors: domain trust, content relevance, fact-checking, bias detection, and citations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # SerpAPI Key\n",
        "        # This api key is acquired from SerpAPI website.\n",
        "        self.serpapi_key = Ali_serp_api\n",
        "\n",
        "        # Load models once to avoid redundant API calls\n",
        "        self.similarity_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "        self.fake_news_classifier_new = pipeline(\"text-classification\", model=\"mrm8488/bert-tiny-finetuned-fake-news-detection\")\n",
        "        self.sentiment_analyzer = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "        self.pipe = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
        "\n",
        "    def fetch_page_content(self, url: str) -> str:\n",
        "        \"\"\" Fetches and extracts text content from the given URL. \"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            return \" \".join([p.text for p in soup.find_all(\"p\")])  # Extract paragraph text\n",
        "        except requests.RequestException:\n",
        "            return \"\"  # Fail gracefully by returning an empty string\n",
        "\n",
        "    def get_domain_trust(self, url: str, content: str) -> int:\n",
        "      \"\"\"Computes the domain trust score based on available data sources.\"\"\"\n",
        "      trust_scores = []\n",
        "\n",
        "      # Hugging Face Fake News Detector\n",
        "      if content:\n",
        "        try:\n",
        "            score = self.get_domain_trust_huggingface(content)\n",
        "            trust_scores.append(score)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Hugging Face Trust Calculation: {e}\")\n",
        "\n",
        "      # Compute final score (average of available scores) safely\n",
        "      return int(sum(trust_scores) / len(trust_scores)) if trust_scores else 50  # Default score is 50 if no data\n",
        "\n",
        "    def get_domain_trust_huggingface(self, content: str) -> int:\n",
        "        \"\"\" Uses a Hugging Face fake news detection model to assess credibility. \"\"\"\n",
        "        if not content:\n",
        "            return 50  # Default score if no content available\n",
        "        result = self.fake_news_classifier_new(content[:1200])[0]  # Process only first 1200 characters\n",
        "        return 100 if result[\"label\"] == \"REAL\" else 40 if result[\"label\"] == \"FAKE\" else 50\n",
        "\n",
        "    def compute_similarity_score(self, user_query: str, content: str) -> int:\n",
        "        \"\"\" Computes semantic similarity between user query and page content. \"\"\"\n",
        "        if not content:\n",
        "            return 0\n",
        "        return int(util.pytorch_cos_sim(self.similarity_model.encode(user_query), self.similarity_model.encode(content)).item() * 100)\n",
        "\n",
        "    def check_facts(self, content: str) -> int:\n",
        "        \"\"\" Cross-checks extracted content with Google Fact Check API. \"\"\"\n",
        "        if not content:\n",
        "            return 50\n",
        "        api_url = f\"https://factchecktools.googleapis.com/v1alpha1/claims:search?query={content[:1000]}\"\n",
        "        try:\n",
        "            response = requests.get(api_url)\n",
        "            data = response.json()\n",
        "            return 90 if \"claims\" in data and data[\"claims\"] else 40\n",
        "        except:\n",
        "            return 50  # Default uncertainty score\n",
        "\n",
        "\n",
        "    def detect_bias(self, content: str) -> int:\n",
        "        \"\"\" Uses NLP sentiment analysis to detect potential bias in content. \"\"\"\n",
        "        if not content:\n",
        "            return 50\n",
        "        sentiment_result = self.sentiment_analyzer(content[:1000])[0]\n",
        "        return 100 if sentiment_result[\"label\"] == \"POSITIVE\" else 50 if sentiment_result[\"label\"] == \"NEUTRAL\" else 35\n",
        "\n",
        "    def get_star_rating(self, score: float) -> tuple:\n",
        "        \"\"\" Converts a score (0-100) into a 1-5 star rating. \"\"\"\n",
        "        stars = max(1, min(5, round(score / 20)))  # Normalize 100-scale to 5-star scale\n",
        "        return stars, \"⭐\" * stars\n",
        "\n",
        "    def generate_explanation(self, domain_trust, similarity_score, fact_check_score, bias_score,  final_score) -> str:\n",
        "        \"\"\" Generates a human-readable explanation for the score. \"\"\"\n",
        "        reasons = []\n",
        "        if domain_trust < 50:\n",
        "            reasons.append(\"The source has low domain authority.\")\n",
        "        if similarity_score < 50:\n",
        "            reasons.append(\"The content is not highly relevant to your query.\")\n",
        "        if fact_check_score < 50:\n",
        "            reasons.append(\"Limited fact-checking verification found.\")\n",
        "        if bias_score < 50:\n",
        "            reasons.append(\"Potential bias detected in the content.\")\n",
        "        #if citation_score < 30:\n",
        "            #reasons.append(\"Few citations found for this content.\")\n",
        "\n",
        "        return \" \".join(reasons) if reasons else \"This source is highly credible and relevant.\"\n",
        "\n",
        "    def rate_url_validity(self, user_query: str, url: str) -> dict:\n",
        "        \"\"\" Main function to evaluate the validity of a webpage. \"\"\"\n",
        "        content = self.fetch_page_content(url)\n",
        "\n",
        "        domain_trust = self.get_domain_trust(url, content)\n",
        "        similarity_score = self.compute_similarity_score(user_query, content)\n",
        "        fact_check_score = self.check_facts(content)\n",
        "        bias_score = self.detect_bias(content)\n",
        "        #citation_score = self.check_google_scholar(url)\n",
        "\n",
        "        final_score = (\n",
        "            (0.50 * domain_trust) +\n",
        "            (0.30 * similarity_score) +\n",
        "            (0.25 * fact_check_score) +\n",
        "            (0.30 * bias_score)\n",
        "            )\n",
        "\n",
        "        stars, icon = self.get_star_rating(final_score)\n",
        "        explanation = self.generate_explanation(domain_trust, similarity_score, fact_check_score, bias_score, final_score)\n",
        "\n",
        "        return {\n",
        "            \"raw_score\": {\n",
        "                \"Domain Trust\": domain_trust,\n",
        "                \"Content Relevance\": similarity_score,\n",
        "                \"Fact-Check Score\": fact_check_score,\n",
        "                \"Final Validity Score\": final_score\n",
        "            },\n",
        "            \"stars\": {\n",
        "                \"score\": stars,\n",
        "                \"icon\": icon\n",
        "            },\n",
        "            \"explanation\": explanation\n",
        "        }"
      ],
      "metadata": {
        "id": "qYRWsNCFLMeC"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Running the Class"
      ],
      "metadata": {
        "id": "vHymm6Kyj3dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the URLValidator class\n",
        "validator = URLValidator()\n",
        "\n",
        "# Define user prompt and URL\n",
        "user_prompt = \"how to make safe investments\"\n",
        "url_to_check = \"https://www.sec.gov/investor/pubs/tenthingstoconsider.htm\"\n",
        "\n",
        "# Run the validation\n",
        "result = validator.rate_url_validity(user_prompt, url_to_check)\n",
        "\n",
        "# Print the results\n",
        "import json\n",
        "print(json.dumps(result, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1wwozuYVKnd",
        "outputId": "56694398-f32e-4abe-db6e-efe1ae1cfa37"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"raw_score\": {\n",
            "    \"Domain Trust\": 50,\n",
            "    \"Content Relevance\": 0,\n",
            "    \"Fact-Check Score\": 50,\n",
            "    \"Final Validity Score\": 52.5\n",
            "  },\n",
            "  \"stars\": {\n",
            "    \"score\": 3,\n",
            "    \"icon\": \"\\u2b50\\u2b50\\u2b50\"\n",
            "  },\n",
            "  \"explanation\": \"The content is not highly relevant to your query.\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}